{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdafd2e3-bd3f-45ed-b134-6fd9ffdf0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class AdamOptimizer:\n",
    "    def __init__(self, params, lr=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize moment estimates\n",
    "        self.m = [tf.Variable(tf.zeros_like(p), trainable=False) for p in params]\n",
    "        self.v = [tf.Variable(tf.zeros_like(p), trainable=False) for p in params]\n",
    "\n",
    "    def apply_gradients(self, grads, t):\n",
    "        for i in range(len(self.params)):\n",
    "            self.m[i].assign(self.beta1 * self.m[i] + (1 - self.beta1) * grads[i])\n",
    "            self.v[i].assign(self.beta2 * self.v[i] + (1 - self.beta2) * tf.square(grads[i]))\n",
    "\n",
    "            # Bias-corrected estimates\n",
    "            m_hat = self.m[i] / (1 - tf.pow(self.beta1, tf.cast(t + 1, tf.float32)))\n",
    "            v_hat = self.v[i] / (1 - tf.pow(self.beta2, tf.cast(t + 1, tf.float32)))\n",
    "\n",
    "            update = -self.lr * m_hat / (tf.sqrt(v_hat) + self.epsilon)\n",
    "            self.params[i].assign_add(update)\n",
    "\n",
    "    def train(self, loss_fn, n_epochs=100):\n",
    "        for epoch in range(n_epochs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss = loss_fn()\n",
    "            grads = tape.gradient(loss, self.params)\n",
    "            self.apply_gradients(grads, epoch)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}: Loss = {float(loss):.4f}, w = {w.numpy()}, b = {b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bedfa36-303a-49d9-819e-96a5ed8a8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple loss: (w - 3)^2 + (b - 1)^2\n",
    "def loss_fn():\n",
    "    return (w - 3)**2 + (b - 1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0639c431-6b84-4c78-9958-ecd693e51577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 5.0000, w = [4.9000006], b = [1.9000007]\n",
      "Epoch 10: Loss = 1.0556, w = [3.9331152], b = [1.0051373]\n",
      "Epoch 20: Loss = 0.1230, w = [3.1601958], b = [0.73729897]\n",
      "Epoch 30: Loss = 0.0433, w = [2.7759838], b = [0.9932178]\n",
      "Epoch 40: Loss = 0.0648, w = [2.7780929], b = [1.0962484]\n",
      "Epoch 50: Loss = 0.0058, w = [2.9404826], b = [0.9850265]\n",
      "Epoch 60: Loss = 0.0030, w = [3.0483694], b = [0.9699673]\n",
      "Epoch 70: Loss = 0.0028, w = [3.0472353], b = [1.0167819]\n",
      "Epoch 80: Loss = 0.0001, w = [3.0041025], b = [1.0026567]\n",
      "Epoch 90: Loss = 0.0003, w = [2.9844701], b = [0.9927366]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([5.0], dtype=tf.float32)\n",
    "b = tf.Variable([2.0], dtype=tf.float32)\n",
    "\n",
    "optimizer = AdamOptimizer(params=[w, b], lr=0.1, beta1=0.9, beta2=0.999)\n",
    "optimizer.train(loss_fn, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d483e50-fc2f-4785-a33c-b66c9dab3101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
