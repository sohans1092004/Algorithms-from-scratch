{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad5e907-af32-4621-92e9-39548523a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CNNModel:\n",
    "    def __init__(self, input_dim):\n",
    "        self.layers = []\n",
    "        self.input_dim = input_dim\n",
    "        self.prev_dim = input_dim  # (H, W, C)\n",
    "\n",
    "    def add_dense(self, units, activation='relu'):\n",
    "        flat_dim = tf.reduce_prod(self.prev_dim)\n",
    "        \n",
    "        W = tf.Variable(tf.random.normal([flat_dim, units], stddev=0.1), trainable=True)\n",
    "        b = tf.Variable(tf.zeros([units]), trainable=True)\n",
    "        \n",
    "        self.layers.append({'W': W, 'b': b, 'activation': activation, 'type': 'dense'})\n",
    "        self.prev_dim = (units,)\n",
    "\n",
    "    def add_convolution(self, filters, kernel_size, stride=1, padding=0, activation='relu'):\n",
    "        height, width, in_channels = self.prev_dim\n",
    "        k_h, k_w = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        \n",
    "        K = tf.Variable(tf.random.normal([filters, k_h, k_w, in_channels], stddev=0.1), trainable=True)\n",
    "        b = tf.Variable(tf.zeros([filters]), trainable=True)\n",
    "\n",
    "        self.layers.append({\n",
    "            'W': K, 'b': b, 'stride': stride, 'padding': padding,\n",
    "            'activation': activation, 'type': 'conv'\n",
    "        })\n",
    "\n",
    "        h_out = (height + 2 * padding - k_h) // stride + 1\n",
    "        w_out = (width + 2 * padding - k_w) // stride + 1\n",
    "        self.prev_dim = (h_out, w_out, filters)\n",
    "\n",
    "    def add_pooling(self, pool_size=2, stride=2):\n",
    "        self.layers.append({'pool_size': pool_size, 'stride': stride, 'type': 'pool'})\n",
    "        \n",
    "        h, w, c = self.prev_dim\n",
    "        \n",
    "        h_out = (h - pool_size) // stride + 1\n",
    "        w_out = (w - pool_size) // stride + 1\n",
    "        self.prev_dim = (h_out, w_out, c)\n",
    "\n",
    "    def _convolve(self, X, K, stride, padding):\n",
    "        batch_size, height, width, in_channels = X.shape\n",
    "        out_channels, k_h, k_w, _ = K.shape\n",
    "\n",
    "        if padding > 0:\n",
    "            X = tf.pad(X, [[0, 0], [padding, padding], [padding, padding], [0, 0]])\n",
    "\n",
    "        h_out = (height + 2 * padding - k_h) // stride + 1\n",
    "        w_out = (width + 2 * padding - k_w) // stride + 1\n",
    "        \n",
    "        output = tf.TensorArray(dtype=tf.float32, size=out_channels)\n",
    "        for oc in range(out_channels):\n",
    "            kernel = K[oc]\n",
    "            out = []\n",
    "            for b in range(batch_size):\n",
    "                single_out = []\n",
    "                for i in range(h_out):\n",
    "                    row = []\n",
    "                    for j in range(w_out):\n",
    "                        region = X[b, i*stride:i*stride+k_h, j*stride:j*stride+k_w, :]\n",
    "                        val = tf.reduce_sum(region * kernel)\n",
    "                        row.append(val)\n",
    "                    single_out.append(row)\n",
    "                out.append(single_out)\n",
    "            output = output.write(oc, tf.convert_to_tensor(out))\n",
    "\n",
    "        output = tf.transpose(output.stack(), perm=[1, 2, 3, 0])\n",
    "        return output\n",
    "\n",
    "    def _max_pool(self, X, pool_size, stride):\n",
    "        batch_size, height, width, channels = X.shape\n",
    "        \n",
    "        h_out = (height - pool_size) // stride + 1\n",
    "        w_out = (width - pool_size) // stride + 1\n",
    "\n",
    "        pooled = []\n",
    "        for b in range(batch_size):\n",
    "            img = X[b]\n",
    "            pooled_img = []\n",
    "            for i in range(h_out):\n",
    "                row = []\n",
    "                for j in range(w_out):\n",
    "                    region = img[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size, :]\n",
    "                    row.append(tf.reduce_max(region, axis=[0, 1]))\n",
    "                pooled_img.append(row)\n",
    "            pooled.append(pooled_img)\n",
    "\n",
    "        return tf.convert_to_tensor(pooled)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X\n",
    "        for layer in self.layers:\n",
    "            if layer['type'] == 'conv':\n",
    "                Z = self._convolve(out, layer['W'], layer['stride'], layer['padding'])\n",
    "                Z = tf.nn.bias_add(Z, layer['b'])\n",
    "                out = self._apply_activation(Z, layer['activation'])\n",
    "            elif layer['type'] == 'pool':\n",
    "                out = self._max_pool(out, layer['pool_size'], layer['stride'])\n",
    "            elif layer['type'] == 'dense':\n",
    "                out = tf.reshape(out, [out.shape[0], -1])\n",
    "                Z = tf.matmul(out, layer['W']) + layer['b']\n",
    "                out = self._apply_activation(Z, layer['activation'])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _apply_activation(self, Z, activation):\n",
    "        if activation == 'relu':\n",
    "            return tf.nn.relu(Z)\n",
    "        elif activation == 'sigmoid':\n",
    "            return tf.nn.sigmoid(Z)\n",
    "        elif activation == 'tanh':\n",
    "            return tf.nn.tanh(Z)\n",
    "        else:\n",
    "            return Z\n",
    "\n",
    "    def train(self, X, Y, epochs=100, lr=0.01, loss_fn='mse'):\n",
    "        optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = self.forward(X)\n",
    "                if loss_fn == 'mse':\n",
    "                    loss = tf.reduce_mean((predictions - Y) ** 2)\n",
    "                elif loss_fn == 'bce':\n",
    "                    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(Y, predictions))\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported loss\")\n",
    "\n",
    "            variables = []\n",
    "            for layer in self.layers:\n",
    "                if 'W' in layer:\n",
    "                    variables.append(layer['W'])\n",
    "                if 'b' in layer:\n",
    "                    variables.append(layer['b'])\n",
    "\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dc88753-6986-4685-9ecf-b043e88cd442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6911\n",
      "Epoch 10, Loss: 0.6266\n",
      "Epoch 20, Loss: 0.4516\n",
      "Epoch 30, Loss: 0.1758\n",
      "Epoch 40, Loss: 0.0277\n",
      "Epoch 50, Loss: 0.0042\n",
      "Epoch 60, Loss: 0.0011\n",
      "Epoch 70, Loss: 0.0004\n",
      "Epoch 80, Loss: 0.0002\n",
      "Epoch 90, Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(input_dim=(8, 8, 1))  \n",
    "model.add_convolution(filters=2, kernel_size=3, stride=1, padding=0, activation='relu')\n",
    "model.add_pooling(pool_size=2, stride=2)\n",
    "model.add_dense(units=10, activation='relu')\n",
    "model.add_dense(units=1, activation='sigmoid')\n",
    "\n",
    "X = tf.random.normal([5, 8, 8, 1])\n",
    "Y = tf.constant([[1.], [0.], [1.], [0.], [1.]])\n",
    "\n",
    "model.train(X, Y, epochs=100, lr=0.01, loss_fn='bce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe059811-1ec8-47b3-a674-525a824d9016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
